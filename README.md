# ğŸŒ¦ï¸ API-Based Weather Data Ingestion & Analytics Pipeline

## ğŸ“– Overview
This project is an end-to-end **API-based data ingestion and analytics pipeline** built using Python and SQLite.  
It demonstrates how real-world data systems ingest external APIs, ensure data correctness, maintain historical records, and generate analytical insights.

The system is designed with **production-minded principles** such as idempotent ingestion, separation of concerns, scalable configuration, aggregation layers, and logging with retries.

---

## ğŸ¯ Key Features
- Multi-city weather data ingestion from public API
- Config-driven architecture (no hardcoded cities)
- Idempotent ingestion with database-level constraints
- Snapshot vs history table design
- Daily and hourly aggregation tables (warehouse-style)
- Cross-city comparative analytics
- Structured logging with retries and timeouts
- SQLite-backed persistence
- CSV and plot-based outputs

---

## ğŸ—ï¸ System Architecture

Weather API
â†“
Ingestion Layer (Python + Requests)
â†“
Validation & Cleaning
â†“
SQLite Database
â”œâ”€â”€ weather_history (immutable snapshots)
â”œâ”€â”€ weather_current (latest per city)
â”œâ”€â”€ weather_daily_summary
â””â”€â”€ weather_hourly_summary
â†“
Analytics Layer (Pandas + SQL)
â†“
CSV Outputs & Plots

---

## ğŸ—‚ï¸ Project Structure

weather-data-pipeline/
â”‚
â”œâ”€â”€ config/
â”‚ â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ ingestion/
â”‚ â””â”€â”€ fetch_weather.py
â”‚
â”œâ”€â”€ database/
â”‚ â”œâ”€â”€ weather.db
â”‚ â”œâ”€â”€ reset_db.py
â”‚ â”œâ”€â”€ check_tables.py
â”‚ â””â”€â”€ check_summary.py
â”‚
â”œâ”€â”€ analysis/
â”‚ â”œâ”€â”€ analyze_weather.py
â”‚ â”œâ”€â”€ build_daily_summary.py
â”‚ â”œâ”€â”€ build_hourly_summary.py
â”‚ â””â”€â”€ cross_city_analysis.py
â”‚
â”œâ”€â”€ outputs/
â”‚ â”œâ”€â”€ cleaned_weather_data.csv
â”‚ â”œâ”€â”€ plots/
â”‚ â””â”€â”€ ingestion.log
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## ğŸ§  Data Modeling Design

### 1ï¸âƒ£ weather_history
- Append-only table
- Stores all raw snapshots
- Prevents duplicates using `(city, api_last_updated)` constraint

### 2ï¸âƒ£ weather_current
- One row per city
- Always represents latest weather snapshot
- Updated using UPSERT logic

### 3ï¸âƒ£ Aggregation Tables
- `weather_daily_summary`: per-city daily metrics
- `weather_hourly_summary`: per-city hourly metrics

This mirrors **real data warehouse design**.

---

## ğŸ” Ingestion Logic
- API calls wrapped with retry & exponential backoff
- Timeouts to prevent hanging requests
- Partial failures handled gracefully (one city failure doesnâ€™t stop pipeline)
- Logs written to both console and file

---

## ğŸ“Š Analytics Capabilities
- Daily & hourly temperature summaries
- Cross-city average temperature comparison
- Temperature variability analysis
- Time-series trend visualization
- CSV exports for downstream use

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Setup environment
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt

2ï¸âƒ£ Configure cities

Edit config/config.yaml:

cities:
  - Kochi
  - Bangalore
  - Mumbai

  3ï¸âƒ£ Run ingestion
python ingestion/fetch_weather.py

4ï¸âƒ£ Build aggregations
python analysis/build_daily_summary.py
python analysis/build_hourly_summary.py

5ï¸âƒ£ Run analytics
python analysis/cross_city_analysis.py

Future Enhancements

Switchable API providers (WeatherAPI â†” OpenWeatherMap)

Automated scheduling (cron / task scheduler)

Anomaly detection

Postgres migration

Dashboard visualization


Tech Stack

Python

Requests

SQLite

Pandas

Matplotlib

YAML

Logging